{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Options -------------\n",
      "batch_size: 20\n",
      "beta1: 0.5\n",
      "beta2: 0.999\n",
      "con_lambda: 10\n",
      "in_ndc: 3\n",
      "in_ngc: 3\n",
      "input_size: 128\n",
      "lrD: 0.0002\n",
      "lrG: 0.0002\n",
      "name: CartoonGAN\n",
      "nb: 8\n",
      "ndf: 32\n",
      "ngf: 64\n",
      "out_ndc: 1\n",
      "out_ngc: 3\n",
      "pre_train_epoch: 10\n",
      "src_data: /home/rongliang/pytorch-CartoonGAN/data_5000/src_data/\n",
      "tgt_data: /home/rongliang/pytorch-CartoonGAN/data_5000/tgt_data/\n",
      "train_epoch: 100\n",
      "vgg_model: /home/rongliang/pytorch-CartoonGAN/vgg19-dcbb9e9d.pth\n",
      "-------------- End ----------------\n",
      "edge-promoting already done\n",
      "---------- Networks initialized -------------\n",
      "generator(\n",
      "  (down_convs): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (1): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (2): ReLU(inplace)\n",
      "    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (10): ReLU(inplace)\n",
      "  )\n",
      "  (resnet_blocks): Sequential(\n",
      "    (0): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (1): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (2): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (3): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (4): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (5): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (6): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "    (7): resnet_block(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv1_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2_norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    )\n",
      "  )\n",
      "  (up_convs): Sequential(\n",
      "    (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (3): ReLU(inplace)\n",
      "    (4): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (7): ReLU(inplace)\n",
      "    (8): Conv2d(64, 3, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
      "    (9): Tanh()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 11406915\n",
      "discriminator(\n",
      "  (convs): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (6): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (8): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (11): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "    (14): LeakyReLU(negative_slope=0.2, inplace)\n",
      "    (15): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): Sigmoid()\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 1128385\n",
      "VGG19(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): ReLU(inplace)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (24): ReLU(inplace)\n",
      "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (26): ReLU(inplace)\n",
      "    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (31): ReLU(inplace)\n",
      "    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): ReLU(inplace)\n",
      "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (35): ReLU(inplace)\n",
      "    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "Total number of parameters: 143667240\n",
      "-----------------------------------------------\n",
      "Pre-training start!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] - time: 118.12, Recon loss: 19.426\n",
      "[2/10] - time: 115.10, Recon loss: 11.648\n",
      "[3/10] - time: 116.25, Recon loss: 9.303\n",
      "[4/10] - time: 115.03, Recon loss: 8.005\n",
      "[5/10] - time: 118.79, Recon loss: 7.110\n",
      "[6/10] - time: 115.31, Recon loss: 6.474\n",
      "[7/10] - time: 115.50, Recon loss: 6.069\n",
      "[8/10] - time: 116.00, Recon loss: 5.710\n",
      "[9/10] - time: 114.87, Recon loss: 5.459\n",
      "[10/10] - time: 114.05, Recon loss: 5.194\n",
      "training start!\n",
      "[1/100] - time: 244.62, Disc loss: 1.422, Gen loss: 1.932, Con loss: 5.229\n",
      "[2/100] - time: 244.04, Disc loss: 0.759, Gen loss: 2.774, Con loss: 5.527\n",
      "[3/100] - time: 244.45, Disc loss: 0.343, Gen loss: 4.032, Con loss: 5.344\n",
      "[4/100] - time: 243.58, Disc loss: 0.246, Gen loss: 4.711, Con loss: 5.214\n",
      "[5/100] - time: 246.21, Disc loss: 0.234, Gen loss: 5.046, Con loss: 5.334\n",
      "[6/100] - time: 246.99, Disc loss: 0.509, Gen loss: 3.538, Con loss: 5.702\n",
      "[7/100] - time: 246.75, Disc loss: 0.464, Gen loss: 3.386, Con loss: 5.956\n",
      "[8/100] - time: 248.35, Disc loss: 0.422, Gen loss: 3.612, Con loss: 5.999\n",
      "[9/100] - time: 247.43, Disc loss: 0.397, Gen loss: 3.719, Con loss: 6.330\n",
      "[10/100] - time: 246.90, Disc loss: 0.384, Gen loss: 3.742, Con loss: 6.460\n",
      "[11/100] - time: 245.52, Disc loss: 0.317, Gen loss: 4.196, Con loss: 6.624\n",
      "[12/100] - time: 247.73, Disc loss: 0.328, Gen loss: 4.151, Con loss: 6.521\n",
      "[13/100] - time: 244.84, Disc loss: 0.310, Gen loss: 4.271, Con loss: 6.895\n",
      "[14/100] - time: 245.72, Disc loss: 0.338, Gen loss: 3.985, Con loss: 7.164\n",
      "[15/100] - time: 246.14, Disc loss: 0.331, Gen loss: 3.997, Con loss: 7.281\n",
      "[16/100] - time: 245.34, Disc loss: 0.303, Gen loss: 4.227, Con loss: 7.541\n",
      "[17/100] - time: 243.58, Disc loss: 0.308, Gen loss: 4.039, Con loss: 7.502\n",
      "[18/100] - time: 246.01, Disc loss: 0.308, Gen loss: 4.176, Con loss: 7.468\n",
      "[19/100] - time: 246.14, Disc loss: 0.596, Gen loss: 3.601, Con loss: 6.809\n",
      "[20/100] - time: 244.73, Disc loss: 0.286, Gen loss: 3.885, Con loss: 7.444\n",
      "[21/100] - time: 243.26, Disc loss: 0.293, Gen loss: 4.068, Con loss: 7.696\n",
      "[22/100] - time: 243.75, Disc loss: 0.296, Gen loss: 4.045, Con loss: 7.725\n",
      "[23/100] - time: 244.93, Disc loss: 0.317, Gen loss: 4.111, Con loss: 8.134\n",
      "[24/100] - time: 242.17, Disc loss: 0.300, Gen loss: 4.123, Con loss: 7.780\n",
      "[25/100] - time: 240.89, Disc loss: 0.294, Gen loss: 4.198, Con loss: 7.871\n",
      "[26/100] - time: 241.02, Disc loss: 0.450, Gen loss: 4.020, Con loss: 7.734\n",
      "[27/100] - time: 241.99, Disc loss: 0.279, Gen loss: 3.798, Con loss: 7.571\n",
      "[28/100] - time: 241.94, Disc loss: 0.290, Gen loss: 4.125, Con loss: 7.864\n",
      "[29/100] - time: 241.64, Disc loss: 0.278, Gen loss: 4.194, Con loss: 8.120\n",
      "[30/100] - time: 240.03, Disc loss: 0.291, Gen loss: 4.301, Con loss: 8.032\n",
      "[31/100] - time: 241.31, Disc loss: 0.299, Gen loss: 4.189, Con loss: 7.991\n",
      "[32/100] - time: 241.30, Disc loss: 0.401, Gen loss: 4.157, Con loss: 7.711\n",
      "[33/100] - time: 240.86, Disc loss: 0.250, Gen loss: 4.100, Con loss: 7.885\n",
      "[34/100] - time: 241.15, Disc loss: 0.269, Gen loss: 4.400, Con loss: 8.213\n",
      "[35/100] - time: 240.57, Disc loss: 0.276, Gen loss: 4.364, Con loss: 7.948\n",
      "[36/100] - time: 240.79, Disc loss: 0.457, Gen loss: 3.834, Con loss: 7.492\n",
      "[37/100] - time: 240.10, Disc loss: 0.276, Gen loss: 4.145, Con loss: 7.811\n",
      "[38/100] - time: 241.34, Disc loss: 0.259, Gen loss: 4.340, Con loss: 7.932\n",
      "[39/100] - time: 241.45, Disc loss: 0.264, Gen loss: 4.376, Con loss: 7.901\n",
      "[40/100] - time: 240.95, Disc loss: 0.272, Gen loss: 4.389, Con loss: 7.933\n",
      "[41/100] - time: 240.70, Disc loss: 0.278, Gen loss: 4.374, Con loss: 7.844\n",
      "[42/100] - time: 240.46, Disc loss: 0.278, Gen loss: 4.447, Con loss: 8.020\n",
      "[43/100] - time: 241.19, Disc loss: 0.263, Gen loss: 4.509, Con loss: 7.954\n",
      "[44/100] - time: 241.49, Disc loss: 0.291, Gen loss: 4.439, Con loss: 7.849\n",
      "[45/100] - time: 241.10, Disc loss: 0.246, Gen loss: 4.494, Con loss: 7.925\n",
      "[46/100] - time: 240.97, Disc loss: 0.280, Gen loss: 4.446, Con loss: 7.874\n",
      "[47/100] - time: 241.72, Disc loss: 0.428, Gen loss: 4.547, Con loss: 7.802\n",
      "[48/100] - time: 240.79, Disc loss: 0.246, Gen loss: 4.020, Con loss: 7.554\n",
      "[49/100] - time: 241.15, Disc loss: 0.230, Gen loss: 4.535, Con loss: 7.979\n",
      "[50/100] - time: 241.28, Disc loss: 0.241, Gen loss: 4.583, Con loss: 7.733\n",
      "[51/100] - time: 241.13, Disc loss: 0.161, Gen loss: 4.382, Con loss: 7.298\n",
      "[52/100] - time: 241.15, Disc loss: 0.157, Gen loss: 4.376, Con loss: 7.203\n",
      "[53/100] - time: 240.56, Disc loss: 0.156, Gen loss: 4.421, Con loss: 7.170\n",
      "[54/100] - time: 242.01, Disc loss: 0.161, Gen loss: 4.429, Con loss: 7.183\n",
      "[55/100] - time: 242.94, Disc loss: 0.169, Gen loss: 4.449, Con loss: 7.285\n",
      "[56/100] - time: 240.78, Disc loss: 0.167, Gen loss: 4.438, Con loss: 7.246\n",
      "[57/100] - time: 240.98, Disc loss: 0.165, Gen loss: 4.505, Con loss: 7.254\n",
      "[58/100] - time: 241.07, Disc loss: 0.180, Gen loss: 4.430, Con loss: 7.358\n",
      "[59/100] - time: 240.79, Disc loss: 0.169, Gen loss: 4.518, Con loss: 7.301\n",
      "[60/100] - time: 241.39, Disc loss: 0.172, Gen loss: 4.563, Con loss: 7.357\n",
      "[61/100] - time: 241.36, Disc loss: 0.179, Gen loss: 4.525, Con loss: 7.437\n",
      "[62/100] - time: 240.32, Disc loss: 0.176, Gen loss: 4.545, Con loss: 7.375\n",
      "[63/100] - time: 241.47, Disc loss: 0.176, Gen loss: 4.564, Con loss: 7.443\n",
      "[64/100] - time: 243.61, Disc loss: 0.178, Gen loss: 4.584, Con loss: 7.415\n",
      "[65/100] - time: 243.10, Disc loss: 0.184, Gen loss: 4.588, Con loss: 7.464\n",
      "[66/100] - time: 242.94, Disc loss: 0.177, Gen loss: 4.583, Con loss: 7.427\n",
      "[67/100] - time: 244.00, Disc loss: 0.195, Gen loss: 4.556, Con loss: 7.579\n",
      "[68/100] - time: 243.24, Disc loss: 0.180, Gen loss: 4.578, Con loss: 7.431\n",
      "[69/100] - time: 243.89, Disc loss: 0.185, Gen loss: 4.623, Con loss: 7.481\n",
      "[70/100] - time: 245.05, Disc loss: 0.186, Gen loss: 4.615, Con loss: 7.492\n",
      "[71/100] - time: 243.44, Disc loss: 0.188, Gen loss: 4.605, Con loss: 7.529\n",
      "[72/100] - time: 244.05, Disc loss: 0.189, Gen loss: 4.616, Con loss: 7.482\n",
      "[73/100] - time: 243.82, Disc loss: 0.193, Gen loss: 4.598, Con loss: 7.536\n",
      "[74/100] - time: 243.78, Disc loss: 0.195, Gen loss: 4.632, Con loss: 7.530\n",
      "[75/100] - time: 244.39, Disc loss: 0.200, Gen loss: 4.581, Con loss: 7.571\n",
      "[76/100] - time: 245.10, Disc loss: 0.172, Gen loss: 4.570, Con loss: 7.363\n",
      "[77/100] - time: 244.44, Disc loss: 0.171, Gen loss: 4.565, Con loss: 7.365\n",
      "[78/100] - time: 243.47, Disc loss: 0.172, Gen loss: 4.595, Con loss: 7.379\n",
      "[79/100] - time: 241.95, Disc loss: 0.173, Gen loss: 4.575, Con loss: 7.390\n",
      "[80/100] - time: 242.58, Disc loss: 0.173, Gen loss: 4.586, Con loss: 7.391\n",
      "[81/100] - time: 243.66, Disc loss: 0.173, Gen loss: 4.571, Con loss: 7.399\n",
      "[82/100] - time: 243.30, Disc loss: 0.173, Gen loss: 4.585, Con loss: 7.398\n",
      "[83/100] - time: 244.42, Disc loss: 0.174, Gen loss: 4.608, Con loss: 7.412\n",
      "[84/100] - time: 244.09, Disc loss: 0.175, Gen loss: 4.601, Con loss: 7.419\n",
      "[85/100] - time: 244.15, Disc loss: 0.174, Gen loss: 4.583, Con loss: 7.413\n",
      "[86/100] - time: 243.33, Disc loss: 0.175, Gen loss: 4.584, Con loss: 7.419\n",
      "[87/100] - time: 244.22, Disc loss: 0.175, Gen loss: 4.590, Con loss: 7.421\n",
      "[88/100] - time: 245.18, Disc loss: 0.176, Gen loss: 4.595, Con loss: 7.433\n",
      "[89/100] - time: 244.56, Disc loss: 0.175, Gen loss: 4.600, Con loss: 7.430\n",
      "[90/100] - time: 243.58, Disc loss: 0.175, Gen loss: 4.602, Con loss: 7.428\n",
      "[91/100] - time: 241.01, Disc loss: 0.175, Gen loss: 4.595, Con loss: 7.432\n",
      "[92/100] - time: 243.68, Disc loss: 0.176, Gen loss: 4.584, Con loss: 7.435\n",
      "[93/100] - time: 244.11, Disc loss: 0.176, Gen loss: 4.597, Con loss: 7.437\n",
      "[94/100] - time: 243.58, Disc loss: 0.175, Gen loss: 4.612, Con loss: 7.434\n",
      "[95/100] - time: 244.01, Disc loss: 0.177, Gen loss: 4.601, Con loss: 7.448\n",
      "[96/100] - time: 242.74, Disc loss: 0.177, Gen loss: 4.586, Con loss: 7.455\n",
      "[97/100] - time: 243.32, Disc loss: 0.176, Gen loss: 4.602, Con loss: 7.443\n",
      "[98/100] - time: 243.43, Disc loss: 0.178, Gen loss: 4.591, Con loss: 7.460\n",
      "[99/100] - time: 244.56, Disc loss: 0.178, Gen loss: 4.591, Con loss: 7.461\n",
      "[100/100] - time: 245.19, Disc loss: 0.178, Gen loss: 4.628, Con loss: 7.462\n",
      "Avg one epoch time: 243.12, total 100 epochs time: 24421.88\n",
      "Training finish!... save training results\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tensorflow\n",
    "CUDA_VISIBLE_DEVICES=1\n",
    "torch.cuda.set_device(0)\n",
    "\n",
    "%run CartoonGAN.py --name CartoonGAN \\\n",
    "                          --src_data /home/rongliang/pytorch-CartoonGAN/data_5000/src_data/ \\\n",
    "                          --tgt_data /home/rongliang/pytorch-CartoonGAN/data_5000/tgt_data/ \\\n",
    "                          --vgg_model /home/rongliang/pytorch-CartoonGAN/vgg19-dcbb9e9d.pth \\\n",
    "                          --batch_size 20 --input_size 128"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch041",
   "language": "python",
   "name": "pytorch041"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
